{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model validation consists of:\n",
    "* Ensuring your model performs as expected on new data\n",
    "* Testing model performance on holdout datasets\n",
    "* Selecting the best model, parameters, and accuracy metrics\n",
    "* Achieving the best accuracy for the data given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T09:40:02.890819Z",
     "start_time": "2019-04-28T09:38:46.813919Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Steps in Modeling: Candy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's tend to have higher accuracy on observations they have seen before. In the candy dataset, predicting the popularity of Skittles will likely have higher accuracy than predicting the popularity of Andes Mints—Skittles is in the dataset, and Andes Mints is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've built a model based on 70% of candies data using the dataset X_train and need to report how accurate the model is at predicting the popularity of the candies the model was built on, and the 30% of candies (X_test) it has never seen. You will use the mean squared error, mse(), as the accuracy metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T09:40:02.967820Z",
     "start_time": "2019-04-28T09:40:02.890819Z"
    }
   },
   "outputs": [],
   "source": [
    "candy = pd.read_csv(r'candy-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the first 5 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T09:40:03.403825Z",
     "start_time": "2019-04-28T09:40:02.976806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
       "0      100 Grand          1       0        1               0       0   \n",
       "1   3 Musketeers          1       0        0               0       1   \n",
       "2       One dime          0       0        0               0       0   \n",
       "3    One quarter          0       0        0               0       0   \n",
       "4      Air Heads          0       1        0               0       0   \n",
       "\n",
       "   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0                 1     0    1         0         0.732         0.860   \n",
       "1                 0     0    1         0         0.604         0.511   \n",
       "2                 0     0    0         0         0.011         0.116   \n",
       "3                 0     0    0         0         0.011         0.511   \n",
       "4                 0     0    0         0         0.906         0.511   \n",
       "\n",
       "   winpercent  \n",
       "0   66.971725  \n",
       "1   67.602936  \n",
       "2   32.261086  \n",
       "3   46.116505  \n",
       "4   52.341465  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T09:40:03.662428Z",
     "start_time": "2019-04-28T09:40:03.423793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.478647</td>\n",
       "      <td>0.468882</td>\n",
       "      <td>50.316764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.500140</td>\n",
       "      <td>0.373116</td>\n",
       "      <td>0.373116</td>\n",
       "      <td>0.276533</td>\n",
       "      <td>0.276533</td>\n",
       "      <td>0.383482</td>\n",
       "      <td>0.433861</td>\n",
       "      <td>0.502654</td>\n",
       "      <td>0.282778</td>\n",
       "      <td>0.285740</td>\n",
       "      <td>14.714357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>22.445341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>39.141056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>47.829754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732000</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>59.863998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>84.180290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chocolate     fruity    caramel  peanutyalmondy     nougat  \\\n",
       "count  85.000000  85.000000  85.000000       85.000000  85.000000   \n",
       "mean    0.435294   0.447059   0.164706        0.164706   0.082353   \n",
       "std     0.498738   0.500140   0.373116        0.373116   0.276533   \n",
       "min     0.000000   0.000000   0.000000        0.000000   0.000000   \n",
       "25%     0.000000   0.000000   0.000000        0.000000   0.000000   \n",
       "50%     0.000000   0.000000   0.000000        0.000000   0.000000   \n",
       "75%     1.000000   1.000000   0.000000        0.000000   0.000000   \n",
       "max     1.000000   1.000000   1.000000        1.000000   1.000000   \n",
       "\n",
       "       crispedricewafer       hard        bar   pluribus  sugarpercent  \\\n",
       "count         85.000000  85.000000  85.000000  85.000000     85.000000   \n",
       "mean           0.082353   0.176471   0.247059   0.517647      0.478647   \n",
       "std            0.276533   0.383482   0.433861   0.502654      0.282778   \n",
       "min            0.000000   0.000000   0.000000   0.000000      0.011000   \n",
       "25%            0.000000   0.000000   0.000000   0.000000      0.220000   \n",
       "50%            0.000000   0.000000   0.000000   1.000000      0.465000   \n",
       "75%            0.000000   0.000000   0.000000   1.000000      0.732000   \n",
       "max            1.000000   1.000000   1.000000   1.000000      0.988000   \n",
       "\n",
       "       pricepercent  winpercent  \n",
       "count     85.000000   85.000000  \n",
       "mean       0.468882   50.316764  \n",
       "std        0.285740   14.714357  \n",
       "min        0.011000   22.445341  \n",
       "25%        0.255000   39.141056  \n",
       "50%        0.465000   47.829754  \n",
       "75%        0.651000   59.863998  \n",
       "max        0.976000   84.180290  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T09:40:03.718341Z",
     "start_time": "2019-04-28T09:40:03.679396Z"
    }
   },
   "outputs": [],
   "source": [
    "X = candy.drop(['winpercent','competitorname'],axis=1)\n",
    "y = candy['winpercent']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T09:40:05.510309Z",
     "start_time": "2019-04-28T09:40:03.732312Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T09:43:17.083237Z",
     "start_time": "2019-04-28T09:43:17.042302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model is fit using X_train and y_train\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Parameter Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T09:42:59.415375Z",
     "start_time": "2019-04-28T09:42:59.397400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! Recalling which parameters were used will be helpful going forward. Model validation and performance rely heavily on which parameters were used, and there is no way to replicate a model without keeping track of the parameters used!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectors of predictions\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T09:40:05.702937Z",
     "start_time": "2019-04-28T09:40:05.662002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model error on seen data: 23.69.\n",
      "Model error on unseen data: 144.02.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# Train/Test Errors\n",
    "train_error = mse(y_true=y_train, y_pred=train_predictions)\n",
    "test_error = mse(y_true=y_test, y_pred=test_predictions)\n",
    "\n",
    "# Print the accuracy for seen and unseen data\n",
    "print(\"Model error on seen data: {0:.2f}.\".format(train_error))\n",
    "print(\"Model error on unseen data: {0:.2f}.\".format(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. When models perform differently on training and testing data, you should look to model validation to ensure you have the best performing model. In the next lesson, you will start building models to validate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seen vs. Unseen data:\n",
    "* Seen data (used for training)\n",
    "* Unseen data (unavailable for training)\n",
    "<img src='Capture.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio Between Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example (Train:Test):\n",
    "* 80:20\n",
    "* 90:10 (used when we have little data)\n",
    "* 70:30 (used when model is computationally expensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T10:08:25.822624Z",
     "start_time": "2019-04-28T10:08:25.792673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 59\n",
      "X_test: 26\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=1111)\n",
    "\n",
    "print('X_train:', X_train.shape[0])\n",
    "print('X_test:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameter in train_test_split:</b>\n",
    "\n",
    "test_size : float, int or None, optional (default=0.25)\n",
    "    If float, should be between 0.0 and 1.0 and represent the proportion\n",
    "    of the dataset to include in the test split. If int, represents the\n",
    "    absolute number of test samples. If None, the value is set to the\n",
    "    complement of the train size. By default, the value is set to 0.25.\n",
    "    The default will change in version 0.21. It will remain 0.25 only\n",
    "    if ``train_size`` is unspecified, otherwise it will complement\n",
    "    the specified ``train_size``.\n",
    "\n",
    "train_size : float, int, or None, (default=None)\n",
    "    If float, should be between 0.0 and 1.0 and represent the\n",
    "    proportion of the dataset to include in the train split. If\n",
    "    int, represents the absolute number of train samples. If None,\n",
    "    the value is automatically set to the complement of the test size.\n",
    "\n",
    "random_state : int, RandomState instance or None, optional (default=None)\n",
    "    If int, random_state is the seed used by the random number generator;\n",
    "    If RandomState instance, random_state is the random number generator;\n",
    "    If None, the random number generator is the RandomState instance used\n",
    "    by `np.random`.\n",
    "\n",
    "shuffle : boolean, optional (default=True)\n",
    "    Whether or not to shuffle the data before splitting. If shuffle=False\n",
    "    then stratify must be None.\n",
    "\n",
    "stratify : array-like or None (default=None)\n",
    "    If not None, data is split in a stratified fashion, using this as\n",
    "    the class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T10:09:13.615809Z",
     "start_time": "2019-04-28T10:09:13.127602Z"
    }
   },
   "source": [
    "### Splitting by Stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to stratify the split (at least) using Target Variable, especially in <b>classification problem</b>. Stratification split ensures the distribution of Target in whole data will be simillar in the test and train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T10:23:35.357384Z",
     "start_time": "2019-04-28T10:23:35.329432Z"
    }
   },
   "outputs": [],
   "source": [
    "diabetes=pd.read_csv(r'diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T10:23:51.356905Z",
     "start_time": "2019-04-28T10:23:51.322957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0            6      148         72       35        0  33.6  0.627   50   \n",
       "1            1       85         66       29        0  26.6  0.351   31   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T10:25:10.590309Z",
     "start_time": "2019-04-28T10:25:10.578328Z"
    }
   },
   "outputs": [],
   "source": [
    "y = diabetes['diabetes']\n",
    "X = diabetes.drop(['diabetes'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T10:42:24.563774Z",
     "start_time": "2019-04-28T10:42:24.545800Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=1111, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the distribution of Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T10:42:25.990533Z",
     "start_time": "2019-04-28T10:42:25.954588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Dist. in y_train: 1    0.348231\n",
      "Name: diabetes, dtype: float64\n",
      "\n",
      "Target Dist. in y_test:: 1    0.350649\n",
      "Name: diabetes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_target = y_train[y_train==1].value_counts()/len(y_train)\n",
    "test_target = y_test[y_test==1].value_counts()/len(y_test)\n",
    "\n",
    "print('Target Dist. in y_train:', train_target)\n",
    "print()\n",
    "print('Target Dist. in y_test::', test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation: Holdout Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do when testing different model? e.g. testing Random Forest with number of trees of 100 versus 1000? Using validation set will help us validate our model\n",
    "<img src='Capture2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T11:41:30.891199Z",
     "start_time": "2019-04-28T11:41:30.850267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 375\n",
      "X_test: 231\n",
      "X_val: 162\n"
     ]
    }
   ],
   "source": [
    "# Do Train_Test_Split Twice\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=1111, stratify = y)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.3, random_state=1111, stratify = y_train)\n",
    "\n",
    "print('X_train:', X_train.shape[0])\n",
    "print('X_test:', X_test.shape[0])\n",
    "print('X_val:', X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use train dataset to train the model\n",
    "* Use valid dataset to validate the model\n",
    "* Use test dataset to check the performance of the data in unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T11:12:00.358288Z",
     "start_time": "2019-04-28T11:11:59.682507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1 Score: 0.7901\n",
      "Model2 Score: 0.8086\n",
      "Model3 Score: 0.7963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#define the model\n",
    "model1 = RandomForestClassifier(n_estimators=10, random_state=11)\n",
    "model2 = RandomForestClassifier(n_estimators=50, random_state=11)\n",
    "model3 = RandomForestClassifier(n_estimators=100, random_state=11)\n",
    "\n",
    "#fitting the model\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "\n",
    "#accuracy score\n",
    "print('Model1 Score:',round(model1.score(X_val,y_val),4))\n",
    "print('Model2 Score:',round(model2.score(X_val,y_val),4))\n",
    "print('Model3 Score:',round(model3.score(X_val,y_val),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Score from validation set shows that RF with n_estimators = 50 is the best. We check the model to the Test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T11:12:03.333498Z",
     "start_time": "2019-04-28T11:12:03.246633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score: 1.0\n",
      "Model Validation Score: 0.8086\n",
      "Model Test Score: 0.7489\n"
     ]
    }
   ],
   "source": [
    "#accuracy score\n",
    "print('Model Train Score:',round(model2.score(X_train,y_train),4))\n",
    "print('Model Validation Score:',round(model2.score(X_val,y_val),4))\n",
    "print('Model Test Score:',round(model2.score(X_test,y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, we have an overfitting model. You can see that the score of train model is higher than the score of validation model and test model. This means our model is only good in seen data, the model will give inaccurate prediction for the unseen data. Tuning the hyperparameter may help reducing the overfitting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A disadvantage of the holdout method is that the performance estimate may be very sensitive to how we partition the training set into the training and validation subsets; the estimate will vary for different samples of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation: Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In k-fold cross-validation, we randomly split the training dataset into k folds without replacement, where k — 1 folds are used for the model training, and one fold is used for performance evaluation. This procedure is repeated k times so that we obtain k models and performance estimates.\n",
    "<img src='Capture3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the average performance of the models based on the different, independent folds to obtain a performance estimate that is less sensitive to the sub-partitioning of the training data compared to the holdout method. Typically, we use k-fold cross-validation for model tuning, that is, finding the optimal hyperparameter values that yields a satisfying generalization performance.\n",
    "<img src='Capture4.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T11:55:31.209179Z",
     "start_time": "2019-04-28T11:55:29.015062Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1, Class dist.: [223 114], Acc: 0.684\n",
      "Fold:  2, Class dist.: [223 114], Acc: 0.658\n",
      "Fold:  3, Class dist.: [219 118], Acc: 0.789\n",
      "Fold:  4, Class dist.: [220 117], Acc: 0.684\n",
      "Fold:  5, Class dist.: [220 117], Acc: 0.816\n",
      "Fold:  6, Class dist.: [217 121], Acc: 0.730\n",
      "Fold:  7, Class dist.: [218 120], Acc: 0.892\n",
      "Fold:  8, Class dist.: [219 119], Acc: 0.784\n",
      "Fold:  9, Class dist.: [218 120], Acc: 0.757\n",
      "Fold: 10, Class dist.: [219 119], Acc: 0.730\n",
      "CV accuracy: 0.752 +/- 0.067\n"
     ]
    }
   ],
   "source": [
    "#Running K-fold CV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Defining Kfold\n",
    "kfold = KFold(n_splits=10,random_state=11).split(X_train,y_train)\n",
    "\n",
    "#Defining the model\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state=11)\n",
    "\n",
    "#Initialize empty list for the scores\n",
    "scores = []\n",
    "\n",
    "#Loop the kfold\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    rfc.fit(X_train.iloc[train], y_train.iloc[train])\n",
    "    score = rfc.score(X_train.iloc[test], y_train.iloc[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Class dist.: %s, Acc: %.3f' % (k+1,np.bincount(y_train.iloc[train]), score))\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out Random Forest with number of trees of 50 has an average accuracy of 0.752. By averaging the accuracy score from cross validation, we can have more information regarding the validity of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T11:57:47.489311Z",
     "start_time": "2019-04-28T11:57:47.470342Z"
    }
   },
   "source": [
    "### Stratified K-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight improvement over the standard k-fold cross-validation approach is stratified k-fold cross-validation, which can yield better bias and variance estimates, especially in cases of unequal class proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T11:58:27.869210Z",
     "start_time": "2019-04-28T11:58:25.443438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1, Class dist.: [219 117], Acc: 0.846\n",
      "Fold:  2, Class dist.: [219 118], Acc: 0.737\n",
      "Fold:  3, Class dist.: [219 118], Acc: 0.737\n",
      "Fold:  4, Class dist.: [219 118], Acc: 0.763\n",
      "Fold:  5, Class dist.: [220 118], Acc: 0.730\n",
      "Fold:  6, Class dist.: [220 118], Acc: 0.784\n",
      "Fold:  7, Class dist.: [220 118], Acc: 0.703\n",
      "Fold:  8, Class dist.: [220 118], Acc: 0.838\n",
      "Fold:  9, Class dist.: [220 118], Acc: 0.622\n",
      "Fold: 10, Class dist.: [220 118], Acc: 0.730\n",
      "CV accuracy: 0.749 +/- 0.062\n"
     ]
    }
   ],
   "source": [
    "#Running K-fold CV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Defining Kfold\n",
    "kfold = StratifiedKFold(n_splits=10,random_state=11).split(X_train,y_train)\n",
    "\n",
    "#Defining the model\n",
    "rfc = RandomForestClassifier(n_estimators = 50, random_state=11)\n",
    "\n",
    "#Initialize empty list for the scores\n",
    "scores = []\n",
    "\n",
    "#Loop the kfold\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    rfc.fit(X_train.iloc[train], y_train.iloc[train])\n",
    "    score = rfc.score(X_train.iloc[test], y_train.iloc[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Class dist.: %s, Acc: %.3f' % (k+1,np.bincount(y_train.iloc[train]), score))\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the previous code example was useful to illustrate how k-fold crossvalidation works, scikit-learn also implements a k-fold cross-validation scorer, which allows us to evaluate our model using stratified k-fold cross-validation less verbosely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:01:32.964715Z",
     "start_time": "2019-04-28T12:01:31.088744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.84615385 0.73684211 0.73684211 0.76315789 0.72972973 0.78378378\n",
      " 0.7027027  0.83783784 0.62162162 0.72972973]\n",
      "CV accuracy: 0.749 +/- 0.062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=rfc, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special case of k-fold cross-validation is the Leave-one-out cross-validation (LOOCV) method. In LOOCV, we set the number\n",
    "of folds equal to the number of training samples (k = n) so that only one training sample is used for testing during each iteration, which is a recommended approach for working with very small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:12:29.665509Z",
     "start_time": "2019-04-28T12:12:29.653527Z"
    }
   },
   "source": [
    "Use when:\n",
    "* The amount of training data is limited\n",
    "* You want the absolute best error estimate for new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:18:14.463177Z",
     "start_time": "2019-04-28T12:18:14.444212Z"
    }
   },
   "source": [
    "Be cautious when:\n",
    "* Computational resources are limited\n",
    "* You have a lot of data\n",
    "* You have a lot of parameters to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter & Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameters</b> are:\n",
    "* Learned or estimated from the data\n",
    "* The result of fitting a model\n",
    "* Used when making future predictions\n",
    "* Not manually set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:21:45.863858Z",
     "start_time": "2019-04-28T12:21:45.850876Z"
    }
   },
   "outputs": [],
   "source": [
    "X = candy.drop(['winpercent','competitorname'],axis=1)\n",
    "y = candy['winpercent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:21:46.631996Z",
     "start_time": "2019-04-28T12:21:46.532157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.74806698  9.42232207  2.22448136 10.07068847  0.8043306   8.91896981\n",
      " -6.1653265   0.44154009 -0.85449954  9.08676286 -5.92836143] 34.53397841468771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "#These are the parameters from linear Regression\n",
    "print(lr.coef_, lr.intercept_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hyperparameters</b> are:\n",
    "* Manually set before the training occurs\n",
    "* Specify how the training is supposed to happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:24:11.225075Z",
     "start_time": "2019-04-28T12:24:11.200116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 50,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 11,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of Random Forest\n",
    "rfc.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators, max_depth, max_features,and min_samples_split are the main hyperparameters for Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select hyperparameters\n",
    "* Run a single model type at different value sets\n",
    "* Create ranges of possible values to select from\n",
    "* Specify a single accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:41:08.911398Z",
     "start_time": "2019-04-28T12:41:08.884440Z"
    }
   },
   "outputs": [],
   "source": [
    "#Example: Using Diabetes dataset\n",
    "y = diabetes['diabetes']\n",
    "X = diabetes.drop(['diabetes'],axis=1)\n",
    "\n",
    "#Split data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=1111, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:46:34.895381Z",
     "start_time": "2019-04-28T12:46:34.883401Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using Random Forest Model\n",
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "#Define the Hyperparameter\n",
    "param_grid = {\"max_depth\": [4, 6, None],\n",
    "              \"max_features\": [1,3,5],\n",
    "              \"min_samples_split\": [0.2,0.3]} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach of grid search is quite simple; it's a brute-force exhaustive search paradigm where we specify a list of values for different hyperparameters, and the computer evaluates the model performance for each combination of those to obtain the optimal combination of values from that set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Benefits: Tests every possible combination\n",
    "* Drawbacks: Additional hyperparameters increase training time exponentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:48:24.289960Z",
     "start_time": "2019-04-28T12:48:12.928362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7728119180633147\n",
      "{'max_depth': 6, 'max_features': 3, 'min_samples_split': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   11.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(estimator=rfc,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5,\n",
    "                  verbose = 3,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train,y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:53:56.861895Z",
     "start_time": "2019-04-28T12:53:24.815224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7672253258845437\n",
      "{'min_samples_split': 0.2, 'max_features': 5, 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=rfc,\n",
    "                  param_distributions=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5,\n",
    "                  n_iter = 10,\n",
    "                  verbose = 3,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "rs.fit(X_train,y_train)\n",
    "\n",
    "print(rs.best_score_)\n",
    "print(rs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:56:20.434874Z",
     "start_time": "2019-04-28T12:56:20.422894Z"
    }
   },
   "source": [
    "#### Implementing The Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:58:57.676889Z",
     "start_time": "2019-04-28T12:58:57.661914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features=5, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=0.2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rs.best_estimator_\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T12:59:06.694514Z",
     "start_time": "2019-04-28T12:59:06.636603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Score: 0.784\n",
      "Model Test Score: 0.7576\n"
     ]
    }
   ],
   "source": [
    "print('Model Train Score:',round(model.score(X_train,y_train),4))\n",
    "print('Model Test Score:',round(model.score(X_test,y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a better result than the previous RF model of Diabetes in section 1.3.2, even though the model is still overfitting. Hyperparameter tuning is a repetitive work and an art of its own, choosing the best set of hyperparameter to be tested needs a lot of experiences and references."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
